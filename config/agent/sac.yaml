agent:
  name: sac
  class: agent.sac.SACAgent
  params:
    obs_dim: ??? # to be specified later
    action_dim: ??? # to be specified later
    action_range: ??? # to be specified later
    device: ${device}
    critic_cfg: ${double_q_critic}
    actor_cfg: ${residual_actor}
    primitive_cfg: ${primitive_actor}
    discount: 0.99
    init_temperature: 0.1
    alpha_lr: 1e-4
    alpha_betas: [0.9, 0.999]
    actor_lr: 1e-4
    actor_betas: [0.9, 0.999]
    actor_update_frequency: 1
    critic_lr: 1e-4
    critic_betas: [0.9, 0.999]
    critic_tau: 0.005
    critic_target_update_frequency: 2
    batch_size: 1024
    learnable_temperature: true
    
double_q_critic:
  class: agent.critic.DoubleQCritic
  params:
    obs_dim: ${agent.params.obs_dim}
    action_dim: ${agent.params.action_dim}
    hidden_dim: 1024
    hidden_depth: 2
    
residual_actor:
  class: agent.residual_actor.InstantiateResidualActor
  params:
    obs_dim: ${agent.params.obs_dim}
    action_dim: ${agent.params.action_dim}
    hidden_depth: 2
    hidden_dim: 1024
    log_std_bounds: [-5, 2]
    bare: true

primitive_actor:
  class: agent.primitives.InstantiatePrimitives
  params:
    action_dim: ${agent.params.action_dim}
    tau: 0.005
    which:
      uniform: false  # false or 0 means deactivated, otherwise used as bound for random func
      target: false
      noop: false
      gait: false
    gait_cfg: ${gait_actor}

gait_actor:
  class: agent.gait.Gait
  params:
    nb_gaussians: 500
    action_len: ${agent.params.action_dim}
    n_frame_repeat: 50  # todo learn this, or infer it using autocorellation or fft
    pow_2: true